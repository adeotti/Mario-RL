{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739899ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypers \n",
    "lr = 0.001\n",
    "_lambda_ = 0.99\n",
    "gamma = 0.99\n",
    "epochs = 10\n",
    "\n",
    "epsilon = 0.2\n",
    "c1 = 0.5\n",
    "\n",
    "kernel = (1,1) # filter shape for the conv layers\n",
    "OUTPUT_CHANNEL = 5\n",
    "numConv = 2\n",
    "numlinear = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5d5ed85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "class policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.numConv = numConv \n",
    "        self.numLinear = numlinear\n",
    "        self.outLinear = 1\n",
    "        self.kernel = kernel\n",
    "        self.channel = OUTPUT_CHANNEL\n",
    "        self.convs = nn.ModuleList(\n",
    "            [nn.LazyConv2d(self.channel,self.kernel) for n in range(self.numConv)]\n",
    "        )\n",
    "        self.linear = nn.ModuleList(\n",
    "            [nn.LazyLinear(7) for n in range(self.numLinear)]\n",
    "        )\n",
    "        \"\"\"self.linear2 = nn.ModuleList(\n",
    "            [nn.LazyLinear() for n in self.numLinear]\n",
    "        )\"\"\"\n",
    "        self.optim = Adam(self.parameters(),lr=lr)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for convs in self.convs:\n",
    "            x = F.relu(convs(x))\n",
    "        x = torch.flatten(x,0)\n",
    "        for linear in self.linear:\n",
    "            x = F.relu(linear(x))\n",
    "        return F.softmax(x,-1)\n",
    "    \n",
    "\n",
    "class value(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.channel = OUTPUT_CHANNEL\n",
    "        self.kernel = kernel\n",
    "        self.numConv = numConv \n",
    "        self.convs = nn.ModuleList(\n",
    "            [nn.LazyConv2d(self.channel,self.kernel) for n in range(self.numConv)]\n",
    "        )\n",
    "        self.linear = nn.LazyLinear(1)\n",
    "        self.optim = Adam(self.parameters(),lr=lr)\n",
    "\n",
    "    def forward(self,x):\n",
    "        for convs in self.convs:\n",
    "            x = F.relu(convs(x))\n",
    "        x = torch.flatten(x)\n",
    "        x = F.relu(self.linear(x))\n",
    "        return F.relu(x,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "68ae5469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.rand((5,240,256), dtype=torch.float)\n",
    "a = value()\n",
    "a(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f04ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<gymnasium.wrappers.frame_stack.LazyFrames at 0x244b1770bd0>,\n",
       "  <gymnasium.wrappers.frame_stack.LazyFrames at 0x244b0e68ea0>,\n",
       "  <gymnasium.wrappers.frame_stack.LazyFrames at 0x244b17723e0>,\n",
       "  <gymnasium.wrappers.frame_stack.LazyFrames at 0x244b123f740>,\n",
       "  <gymnasium.wrappers.frame_stack.LazyFrames at 0x244b123da80>),\n",
       " (3, 1, 5, 6, 0),\n",
       " (tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.)),\n",
       " (tensor([0.0927], grad_fn=<ReluBackward0>),\n",
       "  tensor([0.0927], grad_fn=<ReluBackward0>),\n",
       "  tensor([0.0927], grad_fn=<ReluBackward0>),\n",
       "  tensor([0.0927], grad_fn=<ReluBackward0>),\n",
       "  tensor([0.0927], grad_fn=<ReluBackward0>)),\n",
       " (tensor(-2.0227, grad_fn=<SqueezeBackward1>),\n",
       "  tensor(-2.0227, grad_fn=<SqueezeBackward1>),\n",
       "  tensor(-2.0227, grad_fn=<SqueezeBackward1>),\n",
       "  tensor(-2.0150, grad_fn=<SqueezeBackward1>),\n",
       "  tensor(-1.9380, grad_fn=<SqueezeBackward1>)),\n",
       " (tensor([-0.0927, -0.0927, -0.0927, -0.0927, -0.0927],\n",
       "         grad_fn=<UnbindBackward0>),\n",
       "  tensor([-0.0009, -0.0009, -0.0009, -0.0009, -0.0009],\n",
       "         grad_fn=<UnbindBackward0>),\n",
       "  tensor([-0.0009, -0.0009, -0.0009, -0.0009, -0.0009],\n",
       "         grad_fn=<UnbindBackward0>),\n",
       "  tensor([-0.0009, -0.0009, -0.0009, -0.0009, -0.0009],\n",
       "         grad_fn=<UnbindBackward0>),\n",
       "  tensor([-0.0009, -0.0009, -0.0009, -0.0009, -0.0009],\n",
       "         grad_fn=<UnbindBackward0>)),\n",
       " (False, False, False, False, False))"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import gym_super_mario_bros\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "from gymnasium.wrappers import FrameStack,GrayScaleObservation\n",
    "from gymnasium.spaces import Box\n",
    "\n",
    "import numpy as np\n",
    "from torch.distributions import Categorical\n",
    "from PIL import Image\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "\n",
    "numFrames = 5\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0',apply_api_compatibility=True)\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "env = FrameStack(env,numFrames)\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self):\n",
    "        self.policy = policy()\n",
    "        self.value = value()\n",
    "        self.env = env\n",
    "        self.data = []\n",
    "        self.gamma = gamma\n",
    "        self._lambda_ = _lambda_\n",
    "    \n",
    "    def rollout(self,batchsize):\n",
    "        self.clear()\n",
    "        for _ in range(batchsize):\n",
    "            _image = np.array(self.env.reset()[0])\n",
    "            _list_ = []\n",
    "            for i in range(numFrames): # grayscale frame by frame\n",
    "                _pil = Image.fromarray(_image[i])\n",
    "                _observation = to_tensor(v2.Grayscale(1)(_pil))\n",
    "                _list_.append(_observation)\n",
    "\n",
    "            _states = torch.stack(_list_,dim=0) # --> torch.Size([5, 1, 240, 256])\n",
    "            _distribution = Categorical(self.policy.forward(_states)) \n",
    "            value = self.value.forward(_states)\n",
    "\n",
    "            action = _distribution.sample()\n",
    "            prob = _distribution.log_prob(action)\n",
    "            state,reward,done,_,_ = self.env.step(action.item())\n",
    "            self.data.append([state,torch.tensor(reward),value,prob,action.item(),done])\n",
    "        \n",
    "        # advantages \n",
    "        _,_rewards,_values,_,_,_ = zip(*self.data) \n",
    "        _rewards = torch.stack(_rewards)\n",
    "        _values = torch.stack(_values) \n",
    "        _values = torch.cat((_values,torch.tensor([[0]])))\n",
    "        n = torch.arange(batchsize)\n",
    "        _temporalDifferences  = _rewards[n] + self.gamma*_values[n+1] - _values[n]\n",
    "        _temporalDifferences = torch.flip(_temporalDifferences,dims=[-1])\n",
    "       \n",
    "        _advantage = 0\n",
    "        advantages = _temporalDifferences[n] + (self._lambda_ * self.gamma * _advantage)\n",
    "        advantages = torch.flip(advantages,dims=[-1]) \n",
    "  \n",
    "        for data,item in zip(self.data,advantages): # append advantages to the data \n",
    "            data.append(item)\n",
    "        random.shuffle(self.data) \n",
    "        states,rewards,values,logProb,actions,done,advantages = zip(*self.data)\n",
    "        return  states,actions,rewards,values,logProb,advantages,done\n",
    "\n",
    "    def clear(self):\n",
    "        self.data = []\n",
    "\n",
    "\n",
    "t = Memory()\n",
    "t.rollout(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0608a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.env = env\n",
    "        self.memory = Memory()\n",
    "        self.policy = policy()\n",
    "        self.value = value()\n",
    "        self.batchsize = batchsize\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def save(self):\n",
    "        torch.save(self.policy.state_dict(),\"./Mario.pth\")\n",
    "\n",
    "    def train(self):\n",
    "        for _ in tqdm(range(self.epochs),total=self.epochs):\n",
    "            states,rewards,values,logProb,advantages,done = self.memory.rollout(self.batchsize)\n",
    "\n",
    "            # TODO : compute critic loss\n",
    "            # TODO compute new log probs\n",
    "            # TODO compute loss critic \n",
    "            #  saves data \n",
    "            # test policy\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
